"""Routes for signal-service (Mojo)."""

from typing import Optional, List, Dict, Any
from datetime import datetime
import uuid

from fastapi import APIRouter, HTTPException, Request, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import asyncio
import json
import psycopg2
from psycopg2.extras import RealDictCursor
import os

router = APIRouter()

PG_DSN = os.getenv('TRADING_CHITTI_PG_DSN', 'postgresql://hariprasath@localhost:6432/trading_chitti')


@router.get("/alerts")
async def get_alerts(
    request: Request,
    limit: int = 100,
    offset: int = 0,
    symbol: Optional[str] = None,
    sector: Optional[str] = None,
):
    """Get alerts from signal-service."""
    try:
        client = request.app.state.signal_service
        response = await client.get_alerts(
            limit=limit,
            offset=offset,
            symbol=symbol,
            sector=sector,
        )
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Signal service error: {str(e)}")


@router.get("/alerts/stream")
async def stream_alerts(request: Request):
    """Server-Sent Events stream of real-time alerts.

    This endpoint streams new alerts as they are generated by signal-service.
    """

    async def event_generator():
        """Generate SSE events."""
        try:
            # Send initial connection message
            yield f"data: {json.dumps({'event': 'connected', 'message': 'SSE stream started'})}\n\n"

            # TODO: Implement actual event streaming from Mojo signal-service
            # For now, this is a placeholder that sends heartbeats

            while True:
                if await request.is_disconnected():
                    break

                # Heartbeat every 30 seconds
                await asyncio.sleep(30)
                yield f": heartbeat\n\n"

                # TODO: Get events from signal-service and yield them
                # Example:
                # event = await client.get_next_event()
                # yield f"data: {json.dumps(event)}\n\n"

        except Exception as e:
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


@router.post("/generate")
async def generate_signals(
    request: Request,
    symbol: str,
    indicators: Optional[dict] = None,
    news_context: Optional[dict] = None,
):
    """Generate trading signals for a symbol."""
    try:
        client = request.app.state.signal_service
        response = await client.generate_signals(
            symbol=symbol,
            indicators=indicators,
            news_context=news_context,
        )
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Signal service error: {str(e)}")


@router.get("/patterns/{symbol}")
async def get_patterns(
    request: Request,
    symbol: str,
    pattern_types: Optional[str] = None,
):
    """Get pattern matches for a symbol.

    Args:
        symbol: Stock symbol
        pattern_types: Comma-separated list of pattern types (optional)
    """
    try:
        client = request.app.state.signal_service

        pattern_list = pattern_types.split(",") if pattern_types else None

        response = await client.get_patterns(
            symbol=symbol,
            pattern_types=pattern_list,
        )
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Signal service error: {str(e)}")


# ============================================================================
# Investment Signals (Stock + Sector Based)
# ============================================================================

class StockInSignal(BaseModel):
    """Stock-level investment signal."""
    id: str
    type: str = "stock"
    symbol: str
    name: str
    action: str
    current_price: float
    target_price: float
    stop_loss: float
    expected_return: float
    expected_duration: str
    confidence: float
    success_rate: float
    news_sentiment: float
    news_article_count: int
    rationale: Optional[str] = ""
    sectors: List[str] = []
    timestamp: str


class SectorStock(BaseModel):
    """Stock within a sector signal."""
    symbol: str
    name: str
    current_price: float
    target_price: float
    stop_loss: float
    expected_return: float
    expected_duration: str
    confidence: float


class SectorInSignal(BaseModel):
    """Sector-based investment signal."""
    id: str
    type: str = "sector"
    sector: str
    action: str
    avg_sentiment: float
    article_count: int
    stocks_count: int
    avg_confidence: float
    stocks: List[SectorStock]
    timestamp: str


class ETFSignal(BaseModel):
    """ETF-based investment signal."""
    id: str
    type: str = "etf"
    symbol: str
    name: str
    sector: str
    action: str
    current_price: float
    target_price: float
    stop_loss: float
    expected_return: float
    expected_duration: str
    confidence: float
    avg_sentiment: float
    article_count: int
    underlying_stocks_count: int
    rationale: str
    timestamp: str


class InvestmentSignalsResponse(BaseModel):
    """Response for investment signals endpoint."""
    stock_signals: List[StockInSignal]
    sector_signals: List[SectorInSignal]
    etf_signals: List[ETFSignal]
    metadata: Dict[str, Any]


@router.get("/investment-signals", response_model=InvestmentSignalsResponse)
async def get_investment_signals(
    min_confidence: float = Query(70.0, ge=0, le=100, description="Minimum confidence percentage"),
    min_success_rate: float = Query(60.0, ge=0, le=100, description="Minimum historical success rate"),
    require_news_sentiment: bool = Query(True, description="Require positive news sentiment"),
    limit: int = Query(50, ge=1, le=200, description="Maximum number of stock signals")
):
    """
    Get short-term investment signals with stock-level and sector-based analysis.

    This endpoint combines:
    - Stock-level signals from ML predictions with historical success rates
    - Sector-level signals based on news sentiment aggregation
    - Strict filtering for high-quality opportunities
    - Dynamic duration calculation based on expected move size

    Filters:
    - Confidence ≥ min_confidence (default 70%)
    - Success rate ≥ min_success_rate (default 60%)
    - News sentiment > 0 if require_news_sentiment=true
    """
    try:
        conn = psycopg2.connect(PG_DSN)
        cur = conn.cursor(cursor_factory=RealDictCursor)

        # ========================================
        # 1. Fetch Stock-Level Signals
        # ========================================
        stock_query = """
        WITH stock_success_rates AS (
            -- Calculate 30-day success rate per stock
            SELECT
                symbol,
                COUNT(CASE WHEN prediction_correct THEN 1 END)::float /
                    NULLIF(COUNT(*), 0) * 100 as success_rate
            FROM premarket.predictions
            WHERE prediction_date >= CURRENT_DATE - INTERVAL '30 days'
                AND validated = TRUE
            GROUP BY symbol
        ),
        stock_sentiment AS (
            -- 7-day news sentiment from articles
            SELECT
                ae.symbol,
                AVG(a.sentiment_score) as sentiment_7d,
                COUNT(DISTINCT a.id) as article_count_7d
            FROM news.articles a
            JOIN news.article_entities ae ON a.id = ae.article_id
            WHERE a.published_at >= CURRENT_TIMESTAMP - INTERVAL '7 days'
                AND a.sentiment_score IS NOT NULL
            GROUP BY ae.symbol
        )
        SELECT
            p.symbol,
            p.stock_name as name,
            p.signal_type as action,
            p.base_price as current_price,
            p.target_price,
            CASE
                WHEN p.signal_type = 'CALL' THEN p.base_price * 0.95
                ELSE p.base_price * 1.05
            END as stop_loss,
            p.predicted_move_pct as expected_return,
            p.confidence_score * 100 as confidence,

            -- Success rate with fallback
            COALESCE(
                sr.success_rate,
                ds.top_gainers_success_rate,
                50.0
            ) as success_rate,

            -- Duration based on move size
            CASE
                WHEN ABS(p.predicted_move_pct) > 5 THEN '1-2 days'
                WHEN ABS(p.predicted_move_pct) > 3 THEN '3-5 days'
                ELSE '5-7 days'
            END as expected_duration,

            COALESCE(ss.sentiment_7d, 0) as news_sentiment,
            COALESCE(ss.article_count_7d, 0)::int as news_article_count,
            p.sector,
            p.predicted_at as timestamp

        FROM premarket.predictions p
        LEFT JOIN stock_success_rates sr ON p.symbol = sr.symbol
        LEFT JOIN premarket.daily_stats ds ON p.prediction_date = ds.prediction_date
        LEFT JOIN stock_sentiment ss ON p.symbol = ss.symbol
        WHERE p.prediction_date = CURRENT_DATE
            AND p.confidence_score * 100 >= %s
            AND COALESCE(sr.success_rate, ds.top_gainers_success_rate, 0) >= %s
            AND (NOT %s OR COALESCE(ss.sentiment_7d, 0) > 0)
        ORDER BY p.confidence_score DESC, ABS(p.predicted_move_pct) DESC
        LIMIT %s
        """

        cur.execute(stock_query, (min_confidence, min_success_rate, require_news_sentiment, limit))
        stock_rows = cur.fetchall()

        stock_signals = []
        for row in stock_rows:
            stock_signals.append(StockInSignal(
                id=str(uuid.uuid4()),
                symbol=row['symbol'],
                name=row['name'],
                action='BUY' if row['action'] == 'CALL' else 'SELL',
                current_price=float(row['current_price']),
                target_price=float(row['target_price']),
                stop_loss=float(row['stop_loss']),
                expected_return=float(row['expected_return']),
                expected_duration=row['expected_duration'],
                confidence=float(row['confidence']),
                success_rate=float(row['success_rate']),
                news_sentiment=float(row['news_sentiment']),
                news_article_count=int(row['news_article_count']),
                rationale="",
                sectors=[row['sector']] if row.get('sector') else [],
                timestamp=row['timestamp'].isoformat() if row.get('timestamp') else datetime.now().isoformat()
            ))

        # ========================================
        # 2. Fetch Sector-Level Signals
        # ========================================
        sector_query = """
        WITH sector_trends AS (
            -- Calculate sector sentiment from news.sector_sentiment view
            SELECT
                sector,
                AVG(avg_sentiment) as avg_sentiment,
                SUM(article_count) as article_count,
                MAX(stocks_count) as stocks_count
            FROM news.sector_sentiment
            WHERE date >= CURRENT_DATE - INTERVAL '7 days'
            GROUP BY sector
            HAVING AVG(avg_sentiment) > 0.3
                AND SUM(article_count) >= 5
        )
        SELECT
            st.sector,
            st.avg_sentiment,
            st.article_count::int as article_count,
            st.stocks_count,
            AVG(p.confidence_score * 100) as avg_confidence,

            -- Aggregate top 5 stocks in sector
            json_agg(
                json_build_object(
                    'symbol', p.symbol,
                    'name', p.stock_name,
                    'current_price', p.base_price,
                    'target_price', p.target_price,
                    'stop_loss', CASE
                        WHEN p.signal_type = 'CALL' THEN p.base_price * 0.95
                        ELSE p.base_price * 1.05
                    END,
                    'expected_return', p.predicted_move_pct,
                    'expected_duration', CASE
                        WHEN ABS(p.predicted_move_pct) > 5 THEN '1-2 days'
                        WHEN ABS(p.predicted_move_pct) > 3 THEN '3-5 days'
                        ELSE '5-7 days'
                    END,
                    'confidence', p.confidence_score * 100
                ) ORDER BY p.confidence_score DESC
            ) FILTER (WHERE p.symbol IS NOT NULL) as stocks

        FROM sector_trends st
        JOIN premarket.predictions p ON p.sector = st.sector AND p.prediction_date = CURRENT_DATE
        WHERE p.confidence_score * 100 >= %s
        GROUP BY st.sector, st.avg_sentiment, st.article_count, st.stocks_count
        HAVING COUNT(p.symbol) > 0
        ORDER BY st.avg_sentiment DESC
        LIMIT 10
        """

        cur.execute(sector_query, (min_confidence,))
        sector_rows = cur.fetchall()

        sector_signals = []
        for row in sector_rows:
            stocks_data = row.get('stocks', [])
            if stocks_data:
                # Parse stocks JSON
                stocks = [
                    SectorStock(
                        symbol=stock['symbol'],
                        name=stock['name'],
                        current_price=float(stock['current_price']),
                        target_price=float(stock['target_price']),
                        stop_loss=float(stock['stop_loss']),
                        expected_return=float(stock['expected_return']),
                        expected_duration=stock['expected_duration'],
                        confidence=float(stock['confidence'])
                    )
                    for stock in stocks_data[:5]  # Top 5 stocks
                ]

                sector_signals.append(SectorInSignal(
                    id=str(uuid.uuid4()),
                    sector=row['sector'],
                    action='BUY',  # Sectors with positive sentiment are BUY signals
                    avg_sentiment=float(row['avg_sentiment']),
                    article_count=int(row['article_count']),
                    stocks_count=int(row['stocks_count']),
                    avg_confidence=float(row['avg_confidence']) if row.get('avg_confidence') else 0.0,
                    stocks=stocks,
                    timestamp=datetime.now().isoformat()
                ))

        # ========================================
        # 3. Generate ETF Signals for Sectors
        # ========================================

        # Sector to ETF mapping (based on Indian market ETFs)
        SECTOR_ETF_MAPPING = {
            'Banks': ['BANKBEES', 'BANKIETF', 'BANKETF', 'AXISBNKETF'],
            'Financial Services': ['BANKBEES', 'FINIETF', 'BANKIETF'],
            'Information Technology': ['AXISTECETF', 'ITBEES', 'TECHETF'],
            'Automobile': ['AUTOBEES', 'AUTOIETF'],
            'Healthcare': ['AXISHCETF', 'PHARMAIETF', 'PHARMABEES'],
            'Consumer Goods': ['FMCGIETF', 'CONSUMBEES', 'CONSUMIETF'],
            'FMCG': ['FMCGIETF', 'CONSUMBEES'],
            'Energy': ['ENERGYBEES'],
            'Oil & Gas': ['ENERGYBEES'],
            'Metals': ['METALBEES'],
            'Infrastructure': ['INFRAIETF', 'INFRABEES'],
            'Pharmaceuticals': ['PHARMABEES', 'AXISHCETF'],
            'Media': ['MNC', 'MIDCAPETF'],
        }

        etf_signals = []

        # For each sector signal, generate corresponding ETF signals
        for sector_signal in sector_signals:
            sector = sector_signal.sector
            etf_symbols = SECTOR_ETF_MAPPING.get(sector, [])

            if not etf_symbols:
                # Try to find ETFs by partial sector name match
                sector_lower = sector.lower()
                if 'bank' in sector_lower or 'financ' in sector_lower:
                    etf_symbols = ['BANKBEES', 'BANKIETF']
                elif 'tech' in sector_lower or 'it' in sector_lower:
                    etf_symbols = ['AXISTECETF']
                elif 'auto' in sector_lower:
                    etf_symbols = ['AUTOBEES']
                elif 'pharma' in sector_lower or 'health' in sector_lower:
                    etf_symbols = ['PHARMABEES', 'AXISHCETF']

            # Fetch ETF data for each symbol
            for etf_symbol in etf_symbols[:2]:  # Top 2 ETFs per sector
                try:
                    # Get ETF details from symbols table
                    cur.execute("""
                        SELECT symbol, name
                        FROM md.symbols
                        WHERE symbol = %s AND active = TRUE
                    """, (etf_symbol,))

                    etf_row = cur.fetchone()
                    if not etf_row:
                        continue

                    # Try to get realtime price
                    cur.execute("""
                        SELECT last_price, volume
                        FROM md.realtime_prices
                        WHERE symbol = %s
                        ORDER BY updated_at DESC
                        LIMIT 1
                    """, (etf_symbol,))

                    price_row = cur.fetchone()

                    # Calculate expected return from sector average
                    avg_expected_return = sum(s.expected_return for s in sector_signal.stocks) / len(sector_signal.stocks) if sector_signal.stocks else 3.0

                    # Duration based on expected move
                    duration = '3-5 days' if abs(avg_expected_return) > 3 else '5-7 days'

                    if price_row and price_row['last_price']:
                        current_price = float(price_row['last_price'])
                        target_price = current_price * (1 + avg_expected_return / 100)
                        stop_loss = current_price * 0.95  # 5% stop loss for ETFs
                    else:
                        # No price data available - use placeholder
                        current_price = 0.0
                        target_price = 0.0
                        stop_loss = 0.0

                    rationale = f"ETF tracking {sector} sector. Sector shows positive sentiment ({sector_signal.avg_sentiment:.2f}) with {sector_signal.article_count} supporting news articles. Diversified exposure to {sector_signal.stocks_count} stocks in the sector."

                    etf_signals.append(ETFSignal(
                        id=str(uuid.uuid4()),
                        symbol=etf_row['symbol'],
                        name=etf_row['name'],
                        sector=sector,
                        action='BUY',
                        current_price=current_price,
                        target_price=target_price,
                        stop_loss=stop_loss,
                        expected_return=avg_expected_return,
                        expected_duration=duration,
                        confidence=sector_signal.avg_confidence,
                        avg_sentiment=sector_signal.avg_sentiment,
                        article_count=sector_signal.article_count,
                        underlying_stocks_count=sector_signal.stocks_count,
                        rationale=rationale,
                        timestamp=datetime.now().isoformat()
                    ))

                except Exception as e:
                    # Skip ETFs that cause errors
                    continue

        cur.close()
        conn.close()

        return InvestmentSignalsResponse(
            stock_signals=stock_signals,
            sector_signals=sector_signals,
            etf_signals=etf_signals,
            metadata={
                "filters_applied": {
                    "min_confidence": min_confidence,
                    "min_success_rate": min_success_rate,
                    "news_sentiment_required": require_news_sentiment
                },
                "timestamp": datetime.now().isoformat(),
                "stock_count": len(stock_signals),
                "sector_count": len(sector_signals),
                "etf_count": len(etf_signals)
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch investment signals: {str(e)}")


@router.get("/dashboard")
async def get_dashboard_data(
    limit: int = Query(20, description="Max signals to return"),
    include_closed: bool = Query(True, description="Include recently closed signals")
):
    """
    Aggregated endpoint for dashboard - returns all data in one call.

    Combines:
    - Active signals
    - Recently closed signals
    - Daily statistics
    - Performance metrics

    Reduces API calls from 4-5 to 1.
    """
    try:
        conn = psycopg2.connect(PG_DSN)
        cur = conn.cursor(cursor_factory=RealDictCursor)

        # 1. Get active signals
        cur.execute("""
            SELECT
                signal_id,
                signal_number,
                symbol,
                stock_name,
                sector,
                signal_type,
                entry_price,
                current_price,
                target_price,
                stop_loss,
                expected_profit_pct,
                confidence_score,
                success_rate_pct,
                status,
                validation_status,
                generated_at,
                updated_at,
                expires_at,
                metadata
            FROM intraday.signals
            WHERE status = 'ACTIVE'
            ORDER BY signal_number DESC
            LIMIT %s
        """, (limit,))
        active_signals = [dict(row) for row in cur.fetchall()]

        # 2. Get recently closed signals (if requested)
        closed_signals = []
        if include_closed:
            cur.execute("""
                SELECT
                    signal_id,
                    signal_number,
                    symbol,
                    stock_name,
                    sector,
                    signal_type,
                    entry_price,
                    current_price,
                    exit_price,
                    target_price,
                    stop_loss,
                    expected_profit_pct,
                    actual_profit_pct,
                    confidence_score,
                    success_rate_pct,
                    status,
                    validation_status,
                    generated_at,
                    updated_at,
                    closed_at,
                    metadata
                FROM intraday.signals
                WHERE status IN ('HIT_TARGET', 'HIT_STOPLOSS', 'EXPIRED')
                  AND DATE(generated_at AT TIME ZONE 'Asia/Kolkata') = CURRENT_DATE
                ORDER BY signal_number DESC
                LIMIT %s
            """, (limit,))
            closed_signals = [dict(row) for row in cur.fetchall()]

        # 3. Get today's statistics
        cur.execute("""
            SELECT
                COUNT(*) as total_signals,
                COUNT(*) FILTER (WHERE status = 'ACTIVE') as active_count,
                COUNT(*) FILTER (WHERE status = 'HIT_TARGET') as hits,
                COUNT(*) FILTER (WHERE status = 'HIT_STOPLOSS') as misses,
                COUNT(*) FILTER (WHERE status = 'EXPIRED') as expired,
                AVG(confidence_score) FILTER (WHERE status = 'ACTIVE') as avg_confidence,
                AVG(actual_profit_pct) FILTER (WHERE status = 'HIT_TARGET') as avg_profit_on_hit,
                AVG(actual_profit_pct) FILTER (WHERE status = 'HIT_STOPLOSS') as avg_loss_on_miss
            FROM intraday.signals
            WHERE generated_at >= CURRENT_DATE
        """)
        stats = dict(cur.fetchone())

        # 4. Calculate success rate for today
        if stats['hits'] and (stats['hits'] + stats['misses']) > 0:
            stats['success_rate'] = (stats['hits'] / (stats['hits'] + stats['misses'])) * 100
        else:
            stats['success_rate'] = None

        # 5. Get top performers (last 7 days)
        cur.execute("""
            SELECT
                symbol,
                stock_name,
                COUNT(*) as signal_count,
                COUNT(*) FILTER (WHERE status = 'HIT_TARGET') as wins,
                AVG(actual_profit_pct) FILTER (WHERE status = 'HIT_TARGET') as avg_profit
            FROM intraday.signals
            WHERE generated_at >= CURRENT_DATE - INTERVAL '7 days'
              AND status IN ('HIT_TARGET', 'HIT_STOPLOSS')
            GROUP BY symbol, stock_name
            HAVING COUNT(*) FILTER (WHERE status = 'HIT_TARGET') > 0
            ORDER BY wins DESC, avg_profit DESC
            LIMIT 10
        """)
        top_performers = [dict(row) for row in cur.fetchall()]

        # 6. Get signal type distribution
        cur.execute("""
            SELECT
                signal_type,
                COUNT(*) as count,
                AVG(confidence_score) as avg_confidence,
                COUNT(*) FILTER (WHERE status = 'HIT_TARGET') as hits
            FROM intraday.signals
            WHERE generated_at >= CURRENT_DATE
            GROUP BY signal_type
            ORDER BY count DESC
        """)
        signal_distribution = [dict(row) for row in cur.fetchall()]

        cur.close()
        conn.close()

        return {
            "active_signals": active_signals,
            "closed_signals": closed_signals,
            "statistics": stats,
            "top_performers": top_performers,
            "signal_distribution": signal_distribution,
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "active_count": len(active_signals),
                "closed_count": len(closed_signals)
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch dashboard data: {str(e)}")
